{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AML Final\n",
    "Melissa Stone Rogers, July 24, 2024\n",
    "\n",
    "## Introduction\n",
    "Professional project using Jupyter Lab, python, and needed frameworks to create a data story and pipelined models using the autompg dataset\n",
    "Commands were used on a Mac machine running zsh.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mpg           398 non-null    float64\n",
      " 1   cylinders     398 non-null    int64  \n",
      " 2   displacement  398 non-null    float64\n",
      " 3   horsepower    398 non-null    object \n",
      " 4   weight        398 non-null    int64  \n",
      " 5   acceleration  398 non-null    float64\n",
      " 6   model year    398 non-null    int64  \n",
      " 7   origin        398 non-null    int64  \n",
      " 8   car name      398 non-null    object \n",
      "dtypes: float64(3), int64(4), object(2)\n",
      "memory usage: 28.1+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "autompg = pd.read_csv(\"auto-mpg.csv\")\n",
    "autompg.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mpg  cylinders  displacement horsepower  weight  acceleration  model year  \\\n",
      "0  18.0          8         307.0        130    3504          12.0          70   \n",
      "1  15.0          8         350.0        165    3693          11.5          70   \n",
      "2  18.0          8         318.0        150    3436          11.0          70   \n",
      "3  16.0          8         304.0        150    3433          12.0          70   \n",
      "4  17.0          8         302.0        140    3449          10.5          70   \n",
      "5  15.0          8         429.0        198    4341          10.0          70   \n",
      "6  14.0          8         454.0        220    4354           9.0          70   \n",
      "7  14.0          8         440.0        215    4312           8.5          70   \n",
      "8  14.0          8         455.0        225    4425          10.0          70   \n",
      "9  15.0          8         390.0        190    3850           8.5          70   \n",
      "\n",
      "   origin                   car name  \n",
      "0       1  chevrolet chevelle malibu  \n",
      "1       1          buick skylark 320  \n",
      "2       1         plymouth satellite  \n",
      "3       1              amc rebel sst  \n",
      "4       1                ford torino  \n",
      "5       1           ford galaxie 500  \n",
      "6       1           chevrolet impala  \n",
      "7       1          plymouth fury iii  \n",
      "8       1           pontiac catalina  \n",
      "9       1         amc ambassador dpl  \n",
      "              mpg   cylinders  displacement       weight  acceleration  \\\n",
      "count  398.000000  398.000000    398.000000   398.000000    398.000000   \n",
      "mean    23.514573    5.454774    193.425879  2970.424623     15.568090   \n",
      "std      7.815984    1.701004    104.269838   846.841774      2.757689   \n",
      "min      9.000000    3.000000     68.000000  1613.000000      8.000000   \n",
      "25%     17.500000    4.000000    104.250000  2223.750000     13.825000   \n",
      "50%     23.000000    4.000000    148.500000  2803.500000     15.500000   \n",
      "75%     29.000000    8.000000    262.000000  3608.000000     17.175000   \n",
      "max     46.600000    8.000000    455.000000  5140.000000     24.800000   \n",
      "\n",
      "       model year      origin  \n",
      "count  398.000000  398.000000  \n",
      "mean    76.010050    1.572864  \n",
      "std      3.697627    0.802055  \n",
      "min     70.000000    1.000000  \n",
      "25%     73.000000    1.000000  \n",
      "50%     76.000000    1.000000  \n",
      "75%     79.000000    2.000000  \n",
      "max     82.000000    3.000000  \n"
     ]
    }
   ],
   "source": [
    "print(autompg.head(n=10))\n",
    "print(autompg.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Data Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  318 Test size:  80\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(autompg,\n",
    "                        test_size=0.2, random_state=123)\n",
    "print('Train size: ', len(train_set), 'Test size: ', len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate a Linear Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for linear regression on training data\n",
      "  Default settings\n",
      "Internal parameters:\n",
      "   Bias is  43.621433976443285\n",
      "   Coefficients [-0.00556012 -0.01801839]\n",
      "   Score 0.7024820582511935\n",
      "MAE is   3.2290037032091603\n",
      "RMSE is  4.2789696537676765\n",
      "MSE is  18.309581297864668\n",
      "R^2     0.7024820582511935\n",
      "\n",
      "Results for linear regression on test data\n",
      "MAE is   3.4980689722029554\n",
      "RMSE is  4.343131313113012\n",
      "MSE is  18.862789602942755\n",
      "R^2     0.6765950182605451\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X = train_set[['weight', 'displacement']]\n",
    "y = train_set['mpg']\n",
    "\n",
    "X_test = test_set[['weight', 'displacement']]\n",
    "y_test = test_set['mpg']\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X,y)\n",
    "\n",
    "y_pred = lr_model.predict(X)\n",
    "print('Results for linear regression on training data')\n",
    "print('  Default settings')\n",
    "print('Internal parameters:')\n",
    "print('   Bias is ', lr_model.intercept_)\n",
    "print('   Coefficients', lr_model.coef_)\n",
    "print('   Score', lr_model.score(X,y))\n",
    "print('MAE is  ', mean_absolute_error(y, y_pred))\n",
    "print('RMSE is ', np.sqrt(mean_squared_error(y, y_pred)))\n",
    "print('MSE is ', mean_squared_error(y, y_pred))\n",
    "print('R^2    ', r2_score(y,y_pred))\n",
    "\n",
    "y_test_pred = lr_model.predict(X_test)\n",
    "print()\n",
    "print('Results for linear regression on test data')\n",
    "print('MAE is  ', mean_absolute_error(y_test, y_test_pred))\n",
    "print('RMSE is ', np.sqrt(mean_squared_error(y_test,\n",
    "y_test_pred)))\n",
    "print('MSE is ', mean_squared_error(y_test, y_test_pred))\n",
    "print('R^2    ', r2_score(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stage bias is  23.412578616352203\n",
      "The stage feature coefficients are  [-4.76109404 -1.88955493]\n",
      "Results for linear regression on training data with pipeline\n",
      "MAE is   3.229003703209161\n",
      "RMSE is  4.2789696537676765\n",
      "MSE is  18.309581297864668\n",
      "R^2     0.7024820582511935\n",
      "Results for linear regression on test data with pipeline\n",
      "MAE is   3.4980689722029568\n",
      "RMSE is  4.3431313131130125\n",
      "MSE is  18.862789602942758\n",
      "R^2     0.676595018260545\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Define the pipline\n",
    "autompg_pipe = Pipeline([\n",
    "    ('median_transform', SimpleImputer(strategy='median')),\n",
    "    ('scale_transform', StandardScaler()),\n",
    "    ('lin_reg', LinearRegression())])\n",
    "\n",
    "# Fit the pipeline\n",
    "autompg_pipe.fit(X,y)\n",
    "\n",
    "# Output the intercept and coefficients \n",
    "print(\"The stage bias is \" ,\n",
    "      autompg_pipe.named_steps['lin_reg'].intercept_)\n",
    "print(\"The stage feature coefficients are \",\n",
    "      autompg_pipe.named_steps['lin_reg'].coef_)\n",
    "\n",
    "# Predict and evaluate on training data\n",
    "y_pred = autompg_pipe.predict(X)\n",
    "print('Results for linear regression on training data with pipeline')\n",
    "print('MAE is  ', mean_absolute_error(y, y_pred))\n",
    "print('RMSE is ', np.sqrt(mean_squared_error(y, y_pred)))\n",
    "print('MSE is ', mean_squared_error(y, y_pred))\n",
    "print('R^2    ', r2_score(y, y_pred))\n",
    "\n",
    "# Predict and evaluate on test data\n",
    "y_test_pred = autompg_pipe.predict(X_test)\n",
    "print('Results for linear regression on test data with pipeline')\n",
    "print('MAE is  ', mean_absolute_error(y_test, y_test_pred))\n",
    "print('RMSE is ', np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print('MSE is ', mean_squared_error(y_test, y_test_pred))\n",
    "print('R^2    ', r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stage bias is  23.412578616352206\n",
      "The stage feature coefficients are  [  0.          -1.49502986 -14.1635106  -11.16752447  24.49126934\n",
      "  -4.53461007]\n",
      "Results for linear regression with polynomial features on training data with pipeline\n",
      "MAE is   2.9597527898224114\n",
      "RMSE is  4.053977013800068\n",
      "MSE is  16.43472962841932\n",
      "R^2     0.7329470918695618\n",
      "Results for linear regression with polynomial features on test data with pipeline\n",
      "MAE is   3.1805704976155433\n",
      "RMSE is  4.284941459858176\n",
      "MSE is  18.360723314411516\n",
      "R^2     0.6852030100948552\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "power = 3\n",
    "poly_process = PolynomialFeatures(degree=power, include_bias=False)\n",
    "\n",
    "#Define the pipeline\n",
    "autompg_pipe = Pipeline([\n",
    "    ('median_transform', SimpleImputer(strategy='median')), \n",
    "    ('poly_process', PolynomialFeatures()),\n",
    "    ('scale_transform', StandardScaler()),\n",
    "    ('lin_reg', LinearRegression())])\n",
    "\n",
    "# Fit the pipeline\n",
    "autompg_pipe.fit(X,y)\n",
    "\n",
    "# Output the intercept and coefficients \n",
    "print(\"The stage bias is \" ,\n",
    "      autompg_pipe.named_steps['lin_reg'].intercept_)\n",
    "print(\"The stage feature coefficients are \",\n",
    "      autompg_pipe.named_steps['lin_reg'].coef_)\n",
    "\n",
    "# Predict and evaluate on training data\n",
    "y_pred = autompg_pipe.predict(X)\n",
    "print('Results for linear regression with polynomial features on training data with pipeline')\n",
    "print('MAE is  ', mean_absolute_error(y, y_pred))\n",
    "print('RMSE is ', np.sqrt(mean_squared_error(y, y_pred)))\n",
    "print('MSE is ', mean_squared_error(y, y_pred))\n",
    "print('R^2    ', r2_score(y, y_pred))\n",
    "\n",
    "# Predict and evaluate on test data\n",
    "y_test_pred = autompg_pipe.predict(X_test)\n",
    "print('Results for linear regression with polynomial features on test data with pipeline')\n",
    "print('MAE is  ', mean_absolute_error(y_test, y_test_pred))\n",
    "print('RMSE is ', np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "print('MSE is ', mean_squared_error(y_test, y_test_pred))\n",
    "print('R^2    ', r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "Basic results for models to predict mpg on\n",
    "the auto-mpg data.\n",
    "| Model | Training Features | Set | RMSE | R2 |\n",
    "|:---|:---|:---|:---|:---|\n",
    "|Linear Regression|Weight,Displacement|Training|4.28|70.25|\n",
    "|Linear Regression|Weight,Displacement|Test|4.34|67.67|\n",
    "|Pipeline, Linear Regression|Weight,Displacement|Training|4.28|70.25|\n",
    "|Pipeline, Linear Regression|Weight,Displacement|Test|4.34|67.67|\n",
    "|Pipeline with Polynomial Features, Linear Regression|Weight,Displacement|Training|4.05|73.29|\n",
    "|Pipeline with Polynomial Features, Linear Regression|Weight,Displacement|Test|4.28|68.52|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion of Results\n",
    "The performance of the models improved with each iteration, the pipeline model with the polynomial features performing the best. However, none of the models performed spectacularly- none of the R^2 scores were close to 80%. I do not have a concern of over- or under-fitting on any of the models, as the test models vs the training models performed as expected. I even ran the polynomial pipeline with a higher power and saw no discernable difference in model performance. I think my chosen features are not the best features to predict the target feature, mpg. \n",
    "\n",
    "I was curious, so I duplicated the notebook to run the other features. I still believe that weight is an important feature as it relates to mpg, so I then changed my secondary feature. Cylinders, acceleration, and origin had similar performance numbers as displacement. \n",
    "\n",
    "However, the pipeline with polynomial features, using weight and model year as my training features had significantly improved scores: training RMSE, 2.91 and R^2, 86.26%; test RMSE, 2.11 and R^2, 85.88%. I would imagine this could be due to advancements in car engineering allowing for a more effective use of fuel, thus having better mpg. The advancements that occurred as model years increased must have a strong correlation to the mpg, allowing this variable to be an important predictive feature.   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
